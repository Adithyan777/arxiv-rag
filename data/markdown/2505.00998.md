# Abstract

Human motion synthesis aims to generate plausible human motion sequences, which has raised widespread attention in computer animation. Recent score-based generative models (SGMs) have demonstrated impressive results on this task. However, their training process involves complex curvature trajectories, leading to unstable training processes. In this paper, we propose a Deterministic-to-Stochastic Diverse Latent Feature Mapping (DSDFM) method for human motion synthesis. DSDFM consists of two stages. The first human motion reconstruction stage aims to learn the latent space distribution of human motions. The second diverse motion generation stage aims to build connections between the Gaussian distribution and the latent space distribution of human motions, thereby enhancing the diversity and accuracy of the generated human motions. This stage is achieved by the designed deterministic feature mapping procedure with DerODE and stochastic diverse output generation procedure with DivSDE. DSDFM is easy to train compared to previous SGMs-based methods and can enhance diversity without introducing additional training parameters. Through qualitative and quantitative experiments, DSDFM achieves state-of-the-art results surpassing the latest methods, validating its superiority in human motion synthesis.

# Introduction

Human motion synthesis task aims to generate diverse and high quality 3D human motion sequences. This task has wide-ranging applications, such as human motion understanding, human-robot interactions, and computer graphics. Recent efforts mainly focus on conditional and unconditional human motion generation. Conditional human motion generation aims to generate human motion sequences under some limiting factors, such as music, audio, and action labels. Unconditional human motion generation intends to generate diverse human motions from diverse data, which still presents a significant challenge, especially when the human motion datasets are unstructured. In this paper, we focus on conditional (under the action labels) and unconditional human motion generations, as shown in Figure 1.

Efficiently generating diverse and accurate human motions remains a tremendous challenge, which has led to the development of many different generative models. Recent advancements in deep generative models, including Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), score-based generative models (SGMs), and related techniques, emerge as the dominant approaches for capturing the data distribution. Specifically, VAEs leverage an encoder-decoder network to learn the latent representation of human motion distribution. VAEs require approximate variational or Monte Carlo inference techniques, which tend to be intractable for complex models. GANs utilize a generator and discriminator to generate real-like motions from random noise. Unfortunately, GANs are known to suffer from numerical instability and mode collapse issues. SGMs define a forward diffusion process that maps data to noise by gradually perturbing the input data. Generation corresponds to a reverse process that synthesizes novel data via iterative denoising process. Even though they have presented high fidelity in generation, it is important to note that these methods have the challenge of curve trajectory modeling within diffusion models, as their forward pass is inherently designed to exhibit curvature in SDE, following either a Variance Preserving SDE (VPSDE) or a Variance Exploding SDE (VESDE), leading to unstable training process and slow inference process.

Recent methods, like DDIM, aim to accelerate the inference process by one-step or few-step generator; nevertheless, these methods lead to an obvious performance drop, and the training process is still unstable.

To synthesize diverse and accurate human motions, we propose a novel method called DSDFM for human motion synthesis. The proposed method has straight trajectories and is easy to train compared to previous SGMs methods, while guaranteeing the diversity and accuracy of the generated human motions. The proposed DSDFM consists of two stages. In the first stage, a human motion reconstruction process is designed to learn the latent space distribution of human motions and motion representation. This process is implemented by the Vector Quantized Variational Autoencoders (VQVAE) network. In the second stage, we design a diverse motion generation module, including deterministic feature mapping procedure and stochastic diverse output generation procedure. Deterministic feature mapping procedure aims to explore the optimal solution for building the connections between the Gaussian distribution and the latent space distribution of human motions using the designed Deterministic Ordinary Equation (DerODE) operation. DerODE has a straight training trajectory compared to previous diffusion generative methods and Flow Matching. Although DerODE is easy to train, it is hard to generate highly diverse human motion patterns since DerODE could only provide deterministic output. Therefore, the designed stochastic diverse output generation procedure aims to enhance the diversity of generated human motions through Diverse Stochastic Differential Equations (DivSDE). It is noted that DivSDE operates during the sampling process of the model without introducing additional training processes.

In summary, our main contributions are as follows:

- We propose a novel method called Diverse Latent Feature Mapping (DSDFM) for human motion synthesis. DSDFM is efficient to train and to utilize at sampling process, and can be used for conditional and unconditional generation.
- We propose an optimal solution to build the connection between the Gaussian distribution and the latent space distribution of human motions. In addition, we provide a stochastic diverse output generation process during the sampling process without reintroducing additional training processes.
- The proposed method DSDFM is evaluated on widely-used human motion datasets in the comprehensive experiments. The obtained results demonstrate the effectiveness of the proposed method over the state-of-the-art approaches for conditional and unconditional human motion generation tasks.

# Related Work

## Human Motion Synthesis

Conditional human motion synthesis aims to generate diverse and realistic human motions according to various conditional inputs, such as action labels and music. For example, MDM utilized a diffusion-based generative model for action-conditioned human motion generations, and reported a trade-off between diversity and fidelity of human motions due to the curve trajectory of training and sampling process. MLD proposed to utilize the DDPM in latent space for human motion generations given an input action label, which also encountered the same problem as DDPM. In addition, the unconditional human motion synthesis task also encounters the same issues although a series of achievements have been made in this field. For example, Holden et al. presented a pioneer work in deep unconditional human motion synthesis. Modi employed the style of StyleGAN to synthesize human motions. Unfortunately, these methods usually suffer from mode collapse or mode mixture. In contrast, we propose a novel method for conditional and unconditional human motion synthesis, which is easy to train compared to previous diffusion-based methods while guaranteeing the diversity of generated motions.

## Diffusion Generative Models

Recent years have witnessed a promising potential in modeling data distributions with diffusion generative models using Denoising diffusion probabilistic modeling (DDPM) and score-based generative models (SGMs), which define a forward diffusion process that maps data to noise by gradually perturbing the input data. Variants of SGMs and techniques have been applied to images, audio. For example, Robin et al. proposed latent diffusion models (LDMs) that work on a compressed latent space of lower dimensionality for high-resolution image synthesis. LSGM proposed to train SGMs in a latent space, which relies on the variational autoencoder framework to generate diverse images. However, it is important to note that these methods have the challenge of curve trajectory modeling within diffusion models, as their complex forward and backward processes are inherently designed to exhibit curvature, leading to unstable training process and slow sampling process. Although DDIM and related techniques can shorten the sampling process, they often result in a performance drop. Flow Matching-based methods offer a more robust and stable alternative to diffusion models during the training process. However, the trajectories between source and target distributions remain relatively curved, and more importantly, these methods struggle to produce highly diverse samples, often sacrificing diversity in the training process. In contrast, we propose a generative model DSDFM for human motion generation tasks. This model utilizes straight trajectories, making it easier to train compared to other diffusion models. Additionally, it is capable of generating diverse human motion sequences.

# Preliminary

Score-based diffusion models gradually perturb data by a forward diffusion process, and then reverse it to recover the data. Under the stochastic differential equation (SDE) framework, diffusion models construct a process $$x_t$$ indexed by a continuous time variable $$t \in [0, T]$$, such that $$x_0 \sim p_0$$, for which we have a dataset of i.i.d. samples, and $$x_T \sim p_T$$, we have a tractable form to generate samples efficiently. $$p_0$$ is the data distribution, $$p_r$$ is the prior distribution. The forward diffusion process can be modeled as the solution to an Itô SDE:

$$
dx_t = f(x_t, t)dt + g(t)dw_t
$$

where $$w_t$$ is the standard Wiener process (Brownian motion), $$f(\cdot, t)$$ is a vector valued function called the drift coefficient of $$x_t$$, and $$g(\cdot)$$ is a scalar function known as the diffusion coefficient of $$x_t$$. There are various ways of designing the SDE such that it diffuses the data distribution into a fixed prior distribution. By starting from samples of $$x_T \sim p_r$$ and reversing the process, we can obtain samples $$x_0 \sim p_0$$. The reverse of a diffusion process is also a diffusion process, running backwards in time and given by the reverse-time SDE:

$$
dx_t = [f(x_t, t) - g^2(t) \nabla_{x_t} \log p_t(x_t)]dt + g(t)dw_t
$$

where $$w_t$$ is a standard Wiener process when time flows backwards from $$T$$ to $$0$$, $$dt$$ is an infinitesimal negative timestep. Once the score $$\nabla_{x_t} \log p_t(x_t)$$ is learned, we can derive the reverse diffusion process and simulate it to sample from $$p_0$$.

# The Proposed Method

This paper aims to synthesize diverse and realistic human motion sequences. The overview of the proposed method is shown in Figure 2. The conditional motion generation is performed under the action labels (Action-to-Motion task). Once the action labels are removed, the entire process becomes unconditional motion generation. The training process of the DSDFM mainly involves two stages. The first stage is the human motion reconstruction process, which aims to learn the human motion representation and capture the latent space distribution of human motions. The second stage aims to build the connections between the Gaussian distribution and the latent space distribution using the designed deterministic feature mapping procedure (DerODE). Moreover, we employ the stochastic diverse generation process (DivSDE) to enhance the diversity of generated human motions.

## Human Motion Reconstruction

The human motion reconstruction network aims to learn the representation and the latent space distribution of human motions. In this process, we utilize VQVAE to capture dynamic spatio-temporal features of human motions. Specifically, the input is a sequence of human motion sequence $$E = \{e_1, e_2, ..., e_T\}$$, with the length of $$T$$, where $$e_t \in \mathbb{R}^{V \times C}$$ is denoted by 3D coordinates at time $$t$$, $$C$$ denotes the 3D coordinates of human joints ($$C = 3$$), $$V$$ is the used number of human joints.

The encoder of VQVAE aims to transform motion sequence into latent features, i.e., $$\text{Enc}(E) = z_i \in Z$$. $$z_i$$ is substituted by its closest vector $$k_j$$ using a quantization codebook, where $$j = \arg\min_{k_j \in K} \|z_i - k_j\|$$. The quantized feature is decoded by the decoder network, i.e., $$\text{Dec}(\cdot)$$.

In this work, the encoder (Enc) and decoder (Dec) networks are implemented by the Transformer and GRU modules. For the Transformer process, we project the input human motion sequences into matrices $$Q, K, V$$ by $$W_Q, W_K, W_V$$. The summary of the spatial joints $$M_t$$ is calculated by aggregating all the joint information using the multi-head mechanism. The GRU with parameter $$\theta$$ intends to capture the smoothness property of human motions, and then encode the human motions into latent space $$Z$$. In addition, the decoder (Dec) aims to map the latent space $$Z$$ back to the reconstructed human motion sequence.

The VQVAE is optimized by minimizing the following loss function:

$$
L_{VQ} = L_E + L_{sg} + L_{z}
$$

where $$L_E$$ represents the reconstruction error, $$L_{sg}$$ aims to optimize the codebook, and the last term is to optimize the encoder by pushing $$z$$ close to its nearest latent vector in the codebook. The human motion reconstruction process aims to learn the human motion representation and map the human motions into latent space $$Z$$.

## Diverse Motion Generation

Although we have established the human motion reconstruction, we still cannot generate diverse human motion accordingly. The main reason is that the latent feature space for human motion is rather complicated and hard to sample. Therefore, it is essential to model the latent feature space for human motion by establishing the relationship between a Gaussian distribution and the latent space distribution. Previous diffusion-based generative methods and flow matching methods suffer from instability during training, exhibiting curved trajectories or difficulty in generating diverse samples. To tackle this issue, we innovatively propose a diverse motion generation module to enhance the diversity and accuracy of generated human motion sequences. Diverse motion generation module consists of two steps, i.e., deterministic feature mapping procedure and stochastic diverse output generation procedure.

### Deterministic Feature Mapping Procedure

The deterministic feature mapping procedure is designed to model the relationship between Gaussian distribution $$p_{Z_{t_1}}$$ and the latent distribution for human motion $$p_{Z_{t_0}}$$ efficiently. Specifically, we propose Deterministic Ordinary Equation (DerODE) operation in the deterministic feature mapping procedure by depicting the transformation with the following proposition:

**Proposition 1:** Given the ordinary equation $$dz_t = u(z_t, t)dt$$, where $$u(z_t, t)$$ denotes the drift function, and suppose the probability of data distribution $$z_t$$ is set to be $$p(z_t) = N(\mu_t, \sigma_t)$$ at the time step $$t$$, where $$\mu_t$$ and $$\sigma_t$$ denote the mean and variance of the Gaussian distribution respectively, the drift function $$u(z_t, t)$$ can be shown as:

$$
u(z_t, t) = \frac{\mu_t - z_t}{\sigma_t}
$$

We can utilize this proposition to transform the data across different distributions. Specifically, we need to establish the connections among the latent motion feature space $$p_{Z_{t_0}}$$ and the standard Normal distribution $$p_{Z_{t_1}} = N(0, I)$$ by carefully designing $$\mu_t$$ and $$\sigma_t$$ for the downstream generation task.

To get straighter paths for the training process, we can introduce the optimal transport (OT) theory into this task. The OT problem aims to minimize the displacement cost between two distributions. Thus, we can leverage the transport plan to build connections between two different distributions. The calculation of the optimal transport can be formulated as:

$$
\min_\gamma \sum_{i,j} C_{ij} \gamma_{ij} \quad \text{s.t.} \quad \sum_j \gamma_{ij} = a_i, \sum_i \gamma_{ij} = b_j, \gamma_{ij} \geq 0
$$

where $$C_{ij}$$ denotes the cost distance matrix which can be calculated as $$C_{ij} = \|z_{0,i} - z_{1,j}\|^2$$, where $$z_{0,i} \sim p_{Z_{t_0}}$$ and $$z_{1,j} \sim p_{Z_{t_1}}$$. The optimization process for solving $$\gamma$$ is provided in the appendix.

Then we can obtain the matched data samples $$z_{0,i}, z_{1,j}$$ via the coupling matrix. Hence we can utilize the dynamic process $$p(z, t)$$ on $$t z_{0,i} + (1-t)z_{1,j}$$ and $$t \in [1]$$:

$$
p(z_t, t) = N(t z_{1,j} + (1-t) z_{0,i}, 0)
$$

Meanwhile, we can obtain the drift function $$u(z, t)$$ via using the proposition as below:

$$
u(z_t, t) = \frac{z_{1,j} - z_{0,i}}{t}
$$

Specifically, we can employ a neural network $$v_\theta$$ with matching samples $$z_0, z_1$$ to predict the deterministic drift $$u(x, t)$$ using the drift-estimate loss function:

$$
\min J_{drift} = \mathbb{E}_{z_0, z_1} \|v_\theta(z_t, t) - (z_1 - z_0)\|^2
$$

Moreover, we intend to figure out more consistent results for achieving better performance. That is, the coupling data samples with different time interpolation should have the same drift output as expected. Therefore, we propose drift-consistent loss function:

$$
\min J_{CL} = \mathbb{E}_{t, t'} \|v_\theta(z_t, t) - v_\theta(z_{t'}, t')\|^2
$$

where $$z_t = (1-t)z_0 + t z_1$$, $$z_{t'} = (1-t')z_0 + t' z_1$$.

Finally, we combine the drift-estimate and drift-consistent loss functions for training our proposed DerODE:

$$
\min J_{DerODE} = J_{drift} + \alpha J_{CL}
$$

where $$\alpha$$ denotes the balanced parameter.

It is noticeable that DerODE will not involve complex denoising or score estimation procedures during the training stage. Therefore, it could be much easier to train compared with other diffusion approaches. Once we obtain the optimal solution on $$v$$, we can generate new motion features in the latent space via randomly sampling noise in the standard Gaussian distribution via:

$$
z_{0,i} = z_{1,i} + v_\theta(z_{1,i}, t=1)
$$

where $$z_{1,i} \sim N(0, I)$$ and it can obtain the deterministic output result $$z_{0,i}$$. Finally, we can utilize the decoder Dec to generate human motion as $$E = \text{Dec}(z_{0,i})$$ accordingly.

### Stochastic Diverse Output Generation Procedure

Although we have obtained the deterministic ordinary differential equations (DerODE) between the latent space distribution of human motions and the standard Gaussian distribution, it remains challenging to generate highly diverse motion patterns. This difficulty arises from the deterministic nature of the ODEs, as identical initial conditions result in the same output paths, thereby reducing the diversity of the generated samples. To provide more diverse while accurate human motions, we tend to involve the stochastic differential equations based on the ordinary differential equations in the stochastic diverse output generation procedure.

**Proposition 2:** Given the stochastic differential equations $$dz_t = f(z_t, t)dt + g(t)dw_t$$ with the drift and diffusion terms, the mean $$\mu_t$$ and covariance $$\Sigma_t$$ can be formulated as:

$$
\frac{d\mu_t}{dt} = \mathbb{E}[f(z_t, t)]
$$
$$
\frac{d\Sigma_t}{dt} = \mathbb{E}[(z_t - \mu_t)f(z_t, t)^\top] + \mathbb{E}[f(z_t, t)(z_t - \mu_t)^\top] + g^2(t)
$$

We can observe that the stochastic differential equations can transform the distributions according to the specific settings of drift and diffusion terms, which leads to diverse output results based on this proposition. Therefore, it is intuitive to consider a proper stochastic differential equation with carefully designed $$f(z_t, t)$$ and $$g(t)$$ respectively in the stochastic diverse output generation procedure.

**Proposition 3:** Given the Diverse Stochastic Differential Equations (DivSDE) as $$dz_t = n d w_t$$ with the initial data sample $$x$$ and the noise level $$n$$, the probability of data distribution $$x_t$$ is $$p(z_t) = N((1-t)z_i, n^2 t^2 I)$$ at the time step $$t$$ when $$p(z_0) = N(z_0, 0)$$.

It is obvious that the diffusion term $$n d w_t$$ which involves noise can enhance the diversity of the model output and thus DivSDE is different than DerODE. Note that the stochastic differential equations have the backward process as:

$$
dx_t = -\frac{1}{2t} \nabla_{x_t} \log p(z_t) dt + n d w_t
$$

Specifically, $$\nabla_{x_t} \log p(z_t)$$ can be calculated via:

$$
\nabla_{x_t} \log p(z_t) = \frac{1-t}{t}(z - z_0)
$$

However, it is important to note that we can already obtain $$z_0$$ by utilizing DerODE via $$z_{0,i} = \text{DerODE}(z_{1,i})$$ and it can be further utilized for DivSDE. Therefore, we can rewrite the discrete form of the backward process on DivSDE as follows:

$$
z_{i,t} = A_t z_t + (1-A_t) z_{0,i} + n \epsilon
$$

where $$n$$ denotes the strength of diversity. That is, larger value of $$n$$ will provide more diverse output human motions. Moreover, DivSDE can directly borrow the previously calculated results from DerODE for secondary computations without the need for re-introducing other training processes.

## Model Summary

In summary, the proposed DSDFM can synthesize diverse and accurate human motion sequences through the designed two stages, i.e., human motion reconstruction and diverse motion generation. In the human motion reconstruction stage, we first adopt the human motion reconstruction network to learn a well-structured latent space of human motions through VQVAE network. In the diverse motion generation stage, we tend to build the connections between the Gaussian distribution and latent space of human motions, thereby enhancing the diversity while guaranteeing the accuracy of the generated human motions through the designed deterministic feature mapping procedure with DerODE and stochastic diverse output generation procedure with DivSDE. Specifically, DerODE can provide deterministic output results in an efficient way. Meanwhile, DivSDE can obtain more diverse human motions without introducing additional training process.

**Algorithm 1** The process for generating diverse human motions.

Require: time interval $$T$$, time steps $$\Delta t$$, noise for diversity $$n$$

Ensure: Generated new samples

1. Initialize $$z_1$$ from Gaussian distribution $$N(0, I)$$.
2. Adopt DerODE to obtain $$z_{1,0}$$.
3. $$z_{0,i} = \text{DerODE}(z_{1,i})$$
4. Adopt DivSDE to obtain diverse human motions.
5. For $$t$$ in range $$T, t, 0$$:
   - Obtain the score function as $$\nabla \log p(z_{t,i})$$
   - Obtain the diffusion term
   - Obtain the drift term
   - Obtain the noise term as noise $$n$$
   - Obtain $$z_{t,i}$$
6. Generate the human motion $$\text{Dec}(z_{0,i})$$

# Experiment

In this section, we provide extensive experiments to evaluate the performance of our proposed DSDFM across widely used human motion datasets. We first describe the utilized human motion datasets and implementation details. Subsequently, we present a comparative results analysis of our method with other state-of-the-art approaches on conditional and unconditional human motion synthesis. Additionally, we provide ablation studies to assess the effectiveness of the modules in our method. Finally, we visually showcase the generated diverse human motion sequences to provide a qualitative performance.

## Datasets and Implementation Details

**Datasets.** The experiments are conducted on two widely used motion capture datasets, i.e., HumanAct12 and HumanML3D. HumanAct12 provides 1,191 raw motion sequences, and contains 12 subjects in which 12 categories of actions with per-sequence annotation are provided. HumanML3D dataset is a recent dataset that contains 14,616 motion sequences annotated by 44,970 textual descriptions obtained from AMASS.

**Evaluation metrics.** For a fair comparison, our method employs the following evaluation metrics: Frechet Inception Distance (FID), Kernel Inception Distance (KID), Precision, Recall, Accuracy, Diversity, and Multimodality. FID is the distance between the feature distribution of generated motions and that of the real motions, namely the difference in mean and variance. KID compares skewness as well as the values compared in FID, namely mean and variance. Precision measures the probability that a randomly generated motion falls within the support of the distribution of real data. Recall measures the probability that a real motion falls within the support of the distribution of generated data. Accuracy is measured by the corresponding action recognition model. Diversity measures the variance of the whole motion sequences across the dataset. Multimodality measures the diversity of human motion generated from the same text description. A lower value implies better for FID and KID. Higher Precision, Recall, Accuracy, Diversity, and MultiModality values imply better results.

**Implementation Details.** For the human motion reconstruction process, the VQVAE consists of 4 Transformer layers with 8 heads, and the codebook size is set to 512. The batch size is set to 128, learning rate is initially set to 0.01 with a 0.98 decay every 10 epochs. The proposed method is trained for 500 epochs. For the diverse motion generation process, the time interval $$\Delta t$$ is set to 0.01, and the strength of diversity $$n$$ is set to 0.1. The diffusion step is set to 100. The balanced parameter $$\alpha$$ for $$J_{CL}$$ loss is set to 0.3.

## Experimental Results

### Comparisons on Unconditional Human Motion Synthesis

We compare our method DSDFM with other state-of-the-art methods under the unconditional generation settings on the HumanAct12 dataset.

| Method            | FID   | KID   | Precision | Recall | Diversity | params |
|-------------------|-------|-------|-----------|--------|-----------|--------|
| VPoser CVPR19     | 48.65 | 0.72  | 0.68      | 0.72   | 12.75     | 29M    |
| Action2Motion MM21| 49.76 | 0.68  | 0.70      | 0.71   | 13.80     | 21M    |
| ACTOR CVPR21      | 48.80 | 0.53  | 0.72      | 0.74   | 14.10     | 20M    |
| MDM ICLR23        | 31.92 | 0.96  | 0.66      | 0.62   | 17.00     | 24M    |
| MLD CVPR23        | 14.25 | 0.55  | 0.70      | 0.79   | 16.85     | 27M    |
| Modi CVPR23       | 13.03 | 0.12  | 0.71      | 0.81   | 17.57     | 23M    |
| DSDFM (Ours)      | 12.86 | 0.10  | 0.75      | 0.85   | 18.41     | 15M    |
| Improvement       | 1.31  | 1.67  | 4.17      | 4.93   | 4.78      | 2.50   |

### Comparisons on Conditional Human Motion Synthesis (Action-to-Motion)

| Method                | FID      | Accuracy | Diversity | Multimodality | params |
|-----------------------|----------|----------|-----------|---------------|--------|
| Real                  | 0.02±0.01| 0.997±.001| 6.85±.05 | 2.45±.04      |        |
| Action2Motion MM21    | 0.33±.015| 0.917±.003| 6.87±.066| 2.51±.023     | 20M    |
| ACTOR CVPR21          | 0.12±.000| 0.955±.008| 6.84±.03 | 2.53±.020     | 25M    |
| INR ECCV22            | 0.08±.004| 0.973±.001| 6.88±1.048| 2.56±.040    | 27M    |
| MLD CVPR23            | 0.07±.004| 0.964±.002| 6.83±1.05| 2.82±.38      | 24M    |
| MDM ICLR23            | 0.10±.000| 0.990±.000| 6.86±.05 | 2.52±.010     | 24M    |
| MotionDiffuse TPAMI24 | 0.07±.000| 0.992±.013| 6.85±.02 | 2.46±.020     | 25M    |
| DSDFM (Ours)          | 0.068±.010| 0.994±.001| 6.85±1.008| 2.45±.025   | 15M    |
| Improvement           | 2.85     | 0.21     | -0.01     | 0.21          |        |

### Ablation Studies

We conduct ablation studies to evaluate the effectiveness of each module in our method. The results demonstrate that both the deterministic feature mapping and the stochastic diverse output generation contribute significantly to the performance of DSDFM.

### Qualitative Results

We visually showcase the generated diverse human motion sequences to provide a qualitative performance.

**Figure 1:** Examples of the inference process for human motion synthesis. Our method aims to generate diverse and accurate human motion sequences through the designed generative model.

**Figure 2:** The overview of the proposed method DSDFM. The red arrow denotes the first stage and the green arrow denotes the second stage of DSDFM.

# Conclusion

We propose Deterministic-to-Stochastic Diverse Latent Feature Mapping (DSDFM) for human motion synthesis. DSDFM consists of two stages: human motion reconstruction and diverse motion generation. The deterministic feature mapping procedure (DerODE) enables efficient and straight trajectory training, while the stochastic diverse output generation procedure (DivSDE) enhances diversity without additional training. Extensive experiments demonstrate that DSDFM achieves state-of-the-art performance on both conditional and unconditional human motion synthesis tasks, outperforming existing methods in both accuracy and diversity.