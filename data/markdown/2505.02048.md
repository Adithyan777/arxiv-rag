# Abstract

The acquisition of information-rich images within a limited time budget is crucial in medical imaging. Medical image translation (MIT) can help enhance and supplement existing datasets by generating synthetic images from acquired data. While Generative Adversarial Nets (GANs) and Diffusion Models (DMs) have achieved remarkable success in natural image generation, their benefits—creativity and image realism—do not necessarily transfer to medical applications where highly accurate anatomical information is required. In fact, the imitation of acquisition noise or content hallucination hinders clinical utility. Here, we introduce YODA (You Only Denoise once or Average), a novel 2.5D diffusion-based framework for volumetric MIT. YODA unites diffusion and regression paradigms to produce realistic or noise-free outputs. Furthermore, we propose Expectation-Approximation (ExpA) DM sampling, which draws inspiration from MRI signal averaging. ExpA-sampling suppresses generated noise and, thus, eliminates noise from biasing the evaluation of image quality. Through extensive experiments on four diverse multi-modal datasets—comprising multi-contrast brain MRI and pelvic MRI-CT—we show that diffusion and regression sampling yield similar results in practice. As such, the computational overhead of diffusion sampling does not provide systematic benefits in medical information translation. Building on these insights, we demonstrate that YODA outperforms several state-of-the-art GAN and DM methods. Notably, YODA-generated images are shown to be interchangeable with, or even superior to, physical acquisitions for several downstream tasks. Our findings challenge the presumed advantages of DMs in MIT and pave the way for the practical application of MIT in medical imaging.

# Introduction

The capabilities of learning complex, multi-modal distributions have made Generative Adversarial Nets (GANs) and, moreover, Diffusion Models (DMs) some of the dominant design principles for natural image generation tasks. Both types of models excel at generating realistic-appearing textures and achieve visually ever more pleasing images. This success has also fostered their application for medical image generation. In particular, generating synthetic, complementary target from acquired source modalities in medical image translation (MIT) may be leveraged to expand or improve existing datasets, or to accelerate multi-modal imaging protocols by eliminating redundant acquisitions and thereby reducing acquisition time.

An example in brain magnetic resonance (MR) imaging is the acquisition of T2 fluid-attenuated inversion recovery (FLAIR). Although it is popular for detecting lesions such as white matter hyperintensities (WMHs), a biomarker for several neurological morbidities, the acquisition of FLAIR is slow due to the inversion recovery and, therefore, FLAIR is often acquired at lower resolutions or omitted altogether. Due to this practical utility, MIT is a promising and active research field with a focus on GANs and DMs. Specifically, recent work shows superior performance for DMs, which is often attributed to their explicit likelihood estimation and iterative image refinement during image generation. Furthermore, non-deterministic DM sampling is highlighted for estimating uncertainty.

Yet, there is an important difference between image-to-image (I2I) tasks for medical and natural images. Whereas natural image generation aims to generate realistic and pleasing images, medical images are obtained for the information contained in them, which is ultimately visually inspected or automatically extracted in downstream applications. Thus, the perceptual quality and realism of medical images are irrelevant as long as relevant medical information such as biomarkers or pathologies are contained.

In addition, noise is a common problem during acquisition, generating fine-grained details in medical images. Whereas GANs and DMs' popularity and success can be attributed to the generation of low-level features to create realistic images, in MIT, this implies either replicating acquisition noise or hallucinating about potentially false medical information. While deliberately generating noisy images is, in general, already undesirable and opposes efforts of noise suppression during image acquisition, hallucinating about relevant medical information can even lead to misinterpretation or wrong diagnoses.

MIT, and modality translation in particular, should therefore optimize the preservation of information, i.e., minimize image distortion rather than improve perceptual quality, avoiding hallucination and facilitating downstream analyses by noise suppression. In contrast to DMs and GANs, Regression Models (RMs) are trained with pixel-wise regression losses (also called minimum mean-squared-error models). They approximate the expected value in their respective tasks rather than sampling from probability distributions like DMs and GANs, i.e., by design, RMs do not replicate non-deterministic image features like noise. However, the resulting blurriness and reduced perceptual quality may constitute a domain shift with respect to real images and is suggested to hamper diagnostics.

Here, we systematically compare RMs and DMs for MIT. To this end, we propose YODA, a 2.5D DM operating in the uncompressed pixel space as a multi-purpose approach to volumetric medical I2I tasks. While YODA is designed and trained as a DM, it allows for RM-like sampling by simply using the initial target image prediction without further refinement. In addition, we introduce expectation-approximation (ExpA) sampling. Inspired by the physical paragon in MR imaging, we exploit the probabilistic nature of DMs to generate and average multiple images to eliminate noise. Thus, ExpA sampling allows us to mitigate the perception-distortion tradeoff.

To ultimately assess image distortion, i.e., accuracy in translating medically relevant information in the images, and to test the actual practical suitability of the generated images, we extend common evaluation frameworks by assessing relevant downstream tasks. We find no evidence for systematically superior performance of DMs over RMs in extensive experiments with four large datasets: the Rhineland Study (RS), BraTS, and IXI for multi-contrast brain MRI, as well as the Gold atlas comprising pelvic MRI and CT. Furthermore, we note that the higher perceptual quality of DMs is largely governed by the imitation of noise. This implies that, for the application of MIT, DMs only consume computational resources to simulate acquisition noise, whereas noise-free images, which are preferable for most applications, can be obtained much more efficiently. In addition, our findings question the application of DMs for uncertainty estimation if noise imitation dominates the divergence of diffusion trajectories.

Using these insights, we demonstrate the vast superiority of regression-sampled YODA over several strong GAN and DM baselines. Finally, we show that our synthetic images are largely interchangeable with the acquired images in the assessed downstream tasks and that the learned translation generalizes to unseen datasets.

**Contributions**

- We establish YODA as a novel 2.5D diffusion approach for MIT.
- We address and leverage the volumetric nature of MR images fostering 3D coherency while maintaining computational traceability of uncompressed DMs.
- Based on analytical and empirical observations of the effects of noise in the generation and evaluation of synthetic images, we introduce ExpA sampling to systematically compare diffusion and regression paradigms.
- Using these insights we demonstrate the practical equivalence of diffusion and regression sampling.
- We show the superiority of YODA’s image generation quality over several strong baselines on four different datasets including MRI and CT, asserting the suitability of the generated images for downstream tasks and the generalization to external data.
- We publish the models at github.com/Deep-MI/YODA.

# Related Work

Approaches based on conditional GANs (cGANs) have long dominated MIT. The initial work on 2D cGANs was subsequently extended by ResViT and Ea-GANs. ResViT introduces residual transformer blocks for the generator, whereas Ea-GANs conduct MIT in 3D and add edge information to the GAN loss. Ea-GAN has also shown promising results for deriving FLAIR from diffusion-weighted images.

Recently, DMs were established as state-of-the-art for various natural image generation tasks. DMs operate through many (typically T = 1000) latent images with in- or decreasing levels of noise. While the forward diffusion process gradually adds noise, the generative backward process iteratively recovers the images using a trained neural network. Thus, the trained network can generate realistic images from pure noise. Yet, DMs’ iterative nature demands a high number of function evaluations (NFE). The resulting high computational costs are exacerbated by the 3D nature of most medical image modalities. Still, DMs were widely adopted for MIT tasks.

The pioneering work of SynDiff proposes an adversarial DM for unpaired MIT. The authors added GAN losses to compensate for larger denoising steps, reducing the required NFE. To a similar effect, FastDDPM introduces an accelerated sampling scheme. However, we find that accelerated DM sampling reduces high-frequency details. As we show in later sections, this effect biases the reported metrics for image quality, as perceptual quality is traded for reduced distortion.

A variant of DMs for I2I tasks is diffusion bridges (DBs). DBs use the conditioning images rather than noise as a prior for the generative diffusion process, which can result in a more direct sampling path. DBs have therefore gained popularity for MIT. An example is the adversarial DM SelfRDB which introduced a self-consistency step during sampling, i.e., editing the image until convergence to improve generation accuracy. CMDM uses a dedicated GAN to generate the DBs prior and additionally employs a multi-path shortcut diffusion strategy, i.e., multiple predictions of the DM are averaged to increase translation accuracy and estimate the prediction uncertainty.

To address the challenge of consistency of 3D images in MIT, recent work proposed sampling their 2D slab-based DB using a novel inter-slice trajectory alignment that averages several overlapping predictions. Whereas uncompressed 3D DMs are currently impractical for full-resolution image synthesis due to hardware constraints, a feasible 3D design choice is latent DMs (LDMs). Here, DMs operate in the latent space of separately pre-trained autoencoders to reduce the memory footprints. Hence, full-resolution 3D LDMs are realizable on current hardware, with the notable example of ALDM that combines the DMs with latent SPADE blocks and shows promising results for MR contrast translation.

Despite findings that simple RMs can effectively learn expectation values of images even if trained solely on noisy samples, RMs were rarely considered for MIT, and synthesis results of RMs lacked even anatomically well-defined details such as the gray-white matter (GMWM) contrast or were only applied to small, private datasets and relatively simple tasks. For I2I tasks on natural images, the evaluation of several early DMs considered training the neural denoiser as RMs baselines. This revealed that DMs trade distortion (SSIM and PSNR) for perceptual quality (e.g., Fréchet inception distance, FID, or human preference) owing to the ability to hallucinate high-frequency details. Whereas ablations of the diffusion process were conducted for ALDM, using the neural backbone as a simple RM baseline is commonly omitted. The recent work on medical image denoising showed that single-shot regression sampling of DMs reduces image distortion in comparison to native DM sampling.

# Methods

## Acquisition Noise in Quality Evaluation

To illustrate the bias of image metrics for evaluating MIT with noisy images, we analyze its theoretical implications. Modeling MR acquisition as a complex-valued probabilistic process, the MR magnitude image X is the combination of a hypothetical, true image X and the complex-valued (primarily thermal) acquisition noise n.

Acquiring and averaging N_ex independent images suppresses the noise and, in theory, allows us to approximate the noise-free image X.

However, assuming a sufficient SNR, we simplify the Rician to Gaussian noise. When training GANs and DMs with acquired images, sampling the DM results in noisy images, as they aim to maximize the likelihood of a generated image with respect to the acquired image. Yet, noise replication influences the assessed image quality.

The MSE decomposes into acquisition noise and generated noise. The noise is random by definition and, therefore, unrecoverable and not correlated with the generated noise. Thus, the MSE and the derived PSNR penalize noise creation, favoring solutions with small noise. Similar observations can be made for the SSIM. Conversely, reduced noise is unrealistic and, therefore, impairs the perceptual quality. Hence, the noise amplitude determines the well-described trade-off between perceptual quality and image distortion, i.e., image realism vs. faithful and accurate generation of synthetic images.

## YODA

YODA is based on the foundational design of DDPMs. The forward process uses the noise schedule for t = 1,...,T.

With t = 1,...,T, this results in latent images X_t. Conversely, the generative backward process follows a probabilistic model with the forward process and incorporates knowledge of the data distribution.

In practice, the image is approximated iteratively by predicting the acquired image at each time step t using a trained neural network. Whereas DMs usually predict either the noise-free image or the noise, YODA predicts the velocity. Derived from the evidence lower bound of the probabilistic model, the training objective for velocity prediction is the empirical risk minimization of the velocity differences.

### Algorithm 1: Training YODA

1. For each image pair and time step, apply forward diffusion.
2. Compute the velocity prediction target.
3. Gradient descent step on the velocity loss.

### Algorithm 2: Sampling YODA

1. For each time step, predict the next latent using the velocity prediction.
2. If not the final step, add noise and re-noise.
3. Return the final predicted image.

Using the introduced concepts and notation, we describe our modifications of standard DDPMs in the following:

### 1. 2.5D Diffusion

Operating the neural denoiser on full-resolution 3D images is unfeasible on current hardware due to memory constraints. Thus, we perform a 2.5D diffusion approach: define the diffusion process in 3D, while operating the denoiser on 2D slices, stacking the output to form latent diffusion volumes. Based on this, we include the following 2.5D components:

- Multi-slice inputs: Predict a single slice from a slab formed with the two bi-directional adjacent slices (5 in total) of both the diffusion latent and the conditioning image.
- Orthogonal denoising: Rotate the slicing views (sagittal, coronal, axial) between denoising steps to improve 3D information transfer and combat slicing artifacts.

### 2. Truncated Sampling

As the initial solution remains practically unchanged for many late diffusion steps, we truncate DM sampling by skipping the following 75 low-SNR denoising steps. We only consider t = T, T-4, ..., 1.

### 3. Expectation-Approximation (ExpA) Sampling

DM sampling is non-deterministic due to adding random noise in the backward process. Thus, for each run, the sample has a different noise manifestation. We can thus approximate the DMs expected value analogously to acquisition averages.

For a perfect DM, we would obtain the expected value as the average of multiple samples.

### 4. Efficient Approximation of Expected Values

Let us now investigate the behavior of DMs for the first denoising iteration. Since the prior is pure, uninformative noise, the training objective simplifies. The theoretical minimum of this objective is assumed for the expected value, i.e., a perfect DM would already predict noise-free images in the first sampling operation. This provides a tractable alternative to sampling the DM with multiple runs. We therefore also considered this initial solution of YODA as a sampling method for approximating noise-free images, i.e., regression sampling.

Note that, in general, RMs can be seen as a special case of DMs, where setting T=1 during the training only optimizes the single-step regression prediction from the source images with only vacuous noise as additional input. We omit training dedicated RMs here, as we observed only negligible benefits over regression-sampled DMs.

### 5. 3D Coherency in Regression Sampling

As the denoiser operates in 2D, regression sampling lacks access to 3D information. Thus, to improve the performance of regression sampling, we aggregate the predictions of all three views. Additionally, 2.5D diffusion homogenizes the appearance of individual slices due to orthogonal denoising. For a similar effect for regression sampling, we propose to correct the individual slices that form the volumes via gamma corrections with a set of parameters for each slice. We then optimize the parameters to minimize the intensity differences.

## Datasets and Preprocessing

We obtained a stratified set of 2233 participants of the Rhineland Study (RS), which were split into 1344 for training, 237 for validation, and 600 for testing. 52 additional participants with manual WMH annotation constituted the WMH test set. MR acquisition was conducted at two sites using the same 3T scanner type and protocol. We also tested on 82 Mind-brain-body study (MBB) participants for whom T1w, T2w, and 1 mm FLAIR images were available. T1w and T2w were registered to the FLAIR images and interpolated to 1 mm with FreeSurfer.

The IXI dataset contains T1w, T2w, and proton-density (PD) images from 577 participants (111 withheld for testing) acquired at three different sites equipped with 1.5 or 3T scanners from two vendors. We registered the T1w and PD to the T2w images.

For BraTS, we utilized the training and validation data from the 2023 challenge, randomly selecting 200 cases from the pool of training cases added since the 2020 challenge to obtain a test set with reference tumor segmentation labels. The final models were trained on the remaining training cases combined with the validation set. The BraTS dataset includes data from various centers and protocols, and is provided as normalized and skull-stripped images resampled to a 1 mm resolution. We derived full-brain segmentation masks and, for all but the BraTS dataset, performed robust intensity normalization.

MRI-to-CT translation was performed in 15 participants (4 for testing) of the Gold Atlas, which provided co-registered CT, T1w, and T2w images. We created tissue masks based on intensity thresholds on the T1w images and excluded the upper and lower 5 slices due to decreased quality. We defined the region-of-interest (ROI) for translation as the 3D bounding box of the tissue masks expanded by 5, 10, and 20 axial, coronal, sagittal voxels.

All participants gave informed consent to the respective studies.

## Implementation Details

YODA is parametrized by a U-Net with 5 ResNet blocks (128, 128, 256, 256, 512 channels in the encoder and decoder), group normalization (group size 32), SiLU activation functions, and residual self-attention layers with time-step embedding (1 or 12 heads), resulting in 53M parameters. For our final RS model, we increase the size to 214M parameters. Source image conditioning is realized via channel-wise concatenation. We use the linear (default) and cosine noise schedules with T = 1000. We train YODA with an ADAM optimizer with a learning rate of 1e-4 (chosen from 1e-3, 1e-4, 1e-5), a batch size of 8, and 1000 epochs.

# Experimental Results

We tested YODA for MRI contrast translation in the RS, including assessing generalization to the external MBB dataset and BraTS for T1w, T2w → FLAIR, on IXI for T1w, PD → T2w, and on the pelvic Gold atlas dataset for MRI → CT translation. Example images for brain MRI translation are provided in Figure 3 and for pelvis translation in Figure 5.

First, we analyzed the impact of noise in YODA’s sampling methods on the assessed performance and then benchmarked YODA performance against competing methods. Finally, we demonstrated the benefits of YODA components and design choices in ablation studies.

**Figure 1:** FLAIR images generated by YODA with diffusion, ExpA (N_ex=10), regression sampling, and noised regression images are compared to an acquired image. Note that ExpA resembles regression sampling and achieves crisper edges but loses fine-grained details compared to diffusion sampling.

**Figure 2:** Left: YODA’s perception-distortion trade-off for diffusion (N_ex=1, T=1k), ExpA (N_ex=4, 10), DDIM (T=64, 32, 16, 8), regression (T=1), and noised regression images is quantified using the FID and SSIM in the RS. Right: correlation of noise and FID.

**Figure 3:** Diffusion, ExpA, and regression sampling of YODA is demonstrated against competing methods for T1w, T2w → FLAIR translation on random images of the RS (upper) and BraTS (lower). Note that all sampling methods of YODA allow for a more faithful translation of lesions while avoiding artifacts such as Salt-and-Pepper noise and other unrealistic textures.

## Table I: Performance for RS-trained brain MRI translation (T1w, T2w → FLAIR) for in- and external MBB test sets

| Method         | Time   | SSIM (%)         | PSNR (dB)         | SSIM (%)         | PSNR (dB)         | Dice (%)         | ALVR (%)         | CNR              |
|----------------|--------|------------------|-------------------|------------------|-------------------|------------------|------------------|------------------|
|                | Test set n=600           |                   | MBB set n=82     |                   | WMH test set n=52|                  |                  |
| YODA regr.     | 20 s   | 97.31 ± 0.90     | 33.66 ± 1.95      | 93.25 ± 1.14     | 26.75 ± 1.19      | 58.72 ± 18.51    | 0.30 ± 0.25      | 3.54 ± 0.51      |
| YODA N_ex=10   | 2.5 h  | 97.19 ± 0.93     | 33.79 ± 1.82      | 93.27 ± 1.16     | 26.76 ± 1.22      | 58.48 ± 18.70    | 0.30 ± 0.23      | 3.48 ± 0.49      |
| YODA N_ex=4    | 1 h    | 96.99 ± 0.97     | 33.57 ± 1.76      | 93.14 ± 1.16     | 26.70 ± 1.20      | 58.21 ± 18.62    | 0.31 ± 0.24      | 3.42 ± 0.48      |
| YODA diff.     | 14 h   | 96.07 ± 1.12     | 32.66 ± 1.53      | 92.46 ± 1.20     | 26.42 ± 1.14      | 56.12 ± 19.10    | 0.37 ± 0.30      | 3.18 ± 0.45      |
| SelfRDB        | 90 s   | 95.68 ± 1.10     | 30.75 ± 1.43      | 92.72 ± 1.17     | 27.12 ± 1.37      | 55.73 ± 21.12    | 0.42 ± 0.36      | 3.32 ± 0.66      |
| SynDiff        | 15 s   | 96.18 ± 1.06     | 32.42 ± 1.57      | 92.76 ± 1.24     | 27.32 ± 1.49      | 55.65 ± 19.30    | 0.45 ± 0.36      | 3.27 ± 0.53      |
| ALDM           | 60 s   | 87.92 ± 1.39     | 26.57 ± 2.15      | 89.03 ± 1.86     | 25.77 ± 1.66      | 32.35 ± 22.86    | 1.15 ± 0.89      | 1.32 ± 0.57      |
| ResViT         | 10 s   | 94.72 ± 1.13     | 30.52 ± 1.33      | 90.15 ± 1.49     | 25.66 ± 1.60      | 54.04 ± 19.55    | 0.50 ± 0.41      | 2.96 ± 0.52      |
| Ea-GAN         | 5 s    | 95.76 ± 0.97     | 31.45 ± 1.46      | 92.14 ± 1.08     | 26.79 ± 1.32      | 42.86 ± 20.29    |                  |                  |

# Conclusion

We introduced YODA, a novel 2.5D diffusion-based framework for medical image translation that unites diffusion and regression paradigms. Our systematic comparison of regression and diffusion sampling reveals that, for MIT, the computational overhead of diffusion sampling does not provide systematic benefits over regression sampling. YODA outperforms several state-of-the-art GAN and DM methods across multiple datasets and tasks. The findings challenge the presumed advantages of DMs in MIT and pave the way for practical, efficient, and accurate medical image translation for clinical and research applications.